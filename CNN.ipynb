{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for practicing how to use make and train convolutional neural network using tenesorflow. The model is able to achieve 98.5% accuracy on MNIST dataset after 8,000 iterations. The accuracy can be improved by tra\n",
    "\n",
    "I give full credit to Magnus Erik Hvass Pedersen as a lot of the work here is influenced by him. You can find him at  http://www.hvass-labs.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tep\\Anaconda3\\envs\\untitled1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_row, data_col = 28, 28\n",
    "data_shape = (data_row, data_col)\n",
    "data_size = data_row * data_col\n",
    "class_size = 10\n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper funtion that creates a convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConvLayer(input,              \n",
    "                   num_input_channels, \n",
    "                   filter_size,        \n",
    "                   num_filters):\n",
    "    \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    \n",
    "    biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "    \n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "    layer = layer + biases\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, data_size], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, data_row, data_col, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, class_size], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size1 = 5          \n",
    "num_filters1 = 16         \n",
    "\n",
    "filter_size2 = 5          \n",
    "num_filters2 = 36    \n",
    "\n",
    "fc_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    createConvLayer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    createConvLayer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2_shape = layer_conv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = layer_2_shape[1:4].num_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_conv_layer =  tf.reshape(layer_conv2, [-1, num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(s):\n",
    "    return tf.Variable(tf.truncated_normal(s, stddev=0.05))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,\n",
    "                 use_relu=True): \n",
    "    shape=[num_inputs, num_outputs]\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    biases = new_biases(length=num_outputs)\n",
    "\n",
    "   \n",
    "    layer = tf.matmul(input, weights) + biases    \n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=flat_conv_layer,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=class_size,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-ed5b6a782d1a>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_iterations = 8000\n",
    "data.test.cls = np.array([label.argmax() for label in data.test.labels])\n",
    "\n",
    "feed_dict_test = {x: data.test.images,\n",
    "                  y_true: data.test.labels,\n",
    "                  y_true_cls: data.test.cls}\n",
    "accuracy_points = []\n",
    "cost_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0  accuracy =  0.0909\n",
      "Iteration  100  accuracy =  0.6458\n",
      "Iteration  200  accuracy =  0.8191\n",
      "Iteration  300  accuracy =  0.8715\n",
      "Iteration  400  accuracy =  0.8922\n",
      "Iteration  500  accuracy =  0.9048\n",
      "Iteration  600  accuracy =  0.9131\n",
      "Iteration  700  accuracy =  0.9175\n",
      "Iteration  800  accuracy =  0.9253\n",
      "Iteration  900  accuracy =  0.9313\n",
      "Iteration  1000  accuracy =  0.9323\n",
      "Iteration  1100  accuracy =  0.9372\n",
      "Iteration  1200  accuracy =  0.9408\n",
      "Iteration  1300  accuracy =  0.9438\n",
      "Iteration  1400  accuracy =  0.9436\n",
      "Iteration  1500  accuracy =  0.9502\n",
      "Iteration  1600  accuracy =  0.9509\n",
      "Iteration  1700  accuracy =  0.9534\n",
      "Iteration  1800  accuracy =  0.9561\n",
      "Iteration  1900  accuracy =  0.9575\n",
      "Iteration  2000  accuracy =  0.958\n",
      "Iteration  2100  accuracy =  0.9619\n",
      "Iteration  2200  accuracy =  0.9643\n",
      "Iteration  2300  accuracy =  0.9636\n",
      "Iteration  2400  accuracy =  0.9637\n",
      "Iteration  2500  accuracy =  0.968\n",
      "Iteration  2600  accuracy =  0.9697\n",
      "Iteration  2700  accuracy =  0.9708\n",
      "Iteration  2800  accuracy =  0.9706\n",
      "Iteration  2900  accuracy =  0.9721\n",
      "Iteration  3000  accuracy =  0.971\n",
      "Iteration  3100  accuracy =  0.9705\n",
      "Iteration  3200  accuracy =  0.9729\n",
      "Iteration  3300  accuracy =  0.9757\n",
      "Iteration  3400  accuracy =  0.9759\n",
      "Iteration  3500  accuracy =  0.9774\n",
      "Iteration  3600  accuracy =  0.9761\n",
      "Iteration  3700  accuracy =  0.9756\n",
      "Iteration  3800  accuracy =  0.9763\n",
      "Iteration  3900  accuracy =  0.9793\n",
      "Iteration  4000  accuracy =  0.9803\n",
      "Iteration  4100  accuracy =  0.9767\n",
      "Iteration  4200  accuracy =  0.9797\n",
      "Iteration  4300  accuracy =  0.9804\n",
      "Iteration  4400  accuracy =  0.9797\n",
      "Iteration  4500  accuracy =  0.9809\n",
      "Iteration  4600  accuracy =  0.9802\n",
      "Iteration  4700  accuracy =  0.9808\n",
      "Iteration  4800  accuracy =  0.9811\n",
      "Iteration  4900  accuracy =  0.9811\n",
      "Iteration  5000  accuracy =  0.9824\n",
      "Iteration  5100  accuracy =  0.9816\n",
      "Iteration  5200  accuracy =  0.9818\n",
      "Iteration  5300  accuracy =  0.9821\n",
      "Iteration  5400  accuracy =  0.9825\n",
      "Iteration  5500  accuracy =  0.9827\n",
      "Iteration  5600  accuracy =  0.9818\n",
      "Iteration  5700  accuracy =  0.9805\n",
      "Iteration  5800  accuracy =  0.9823\n",
      "Iteration  5900  accuracy =  0.9833\n",
      "Iteration  6000  accuracy =  0.9832\n",
      "Iteration  6100  accuracy =  0.9836\n",
      "Iteration  6200  accuracy =  0.9846\n",
      "Iteration  6300  accuracy =  0.9833\n",
      "Iteration  6400  accuracy =  0.983\n",
      "Iteration  6500  accuracy =  0.9844\n",
      "Iteration  6600  accuracy =  0.9838\n",
      "Iteration  6700  accuracy =  0.9844\n",
      "Iteration  6800  accuracy =  0.9827\n",
      "Iteration  6900  accuracy =  0.9848\n",
      "Iteration  7000  accuracy =  0.9858\n",
      "Iteration  7100  accuracy =  0.9835\n",
      "Iteration  7200  accuracy =  0.9838\n",
      "Iteration  7300  accuracy =  0.9838\n",
      "Iteration  7400  accuracy =  0.9837\n",
      "Iteration  7500  accuracy =  0.9833\n",
      "Iteration  7600  accuracy =  0.9843\n",
      "Iteration  7700  accuracy =  0.9849\n",
      "Iteration  7800  accuracy =  0.9863\n",
      "Iteration  7900  accuracy =  0.9856\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iterations):\n",
    "        x_batch, y_true_batch = data.train.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "            cost_points += [float(cost.eval(feed_dict_train, session))]\n",
    "            accuracy_points += [float(acc)]\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "                print(\"Iteration \", i, \" accuracy = \", acc)\n",
    "        \n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
